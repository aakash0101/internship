{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68840f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.18.1-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in ./anaconda3/lib/python3.11/site-packages (from selenium) (1.26.16)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.24.0-py3-none-any.whl (460 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m460.2/460.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in ./anaconda3/lib/python3.11/site-packages (from selenium) (2023.5.7)\n",
      "Collecting typing_extensions>=4.9.0 (from selenium)\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: attrs>=20.1.0 in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in ./anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in ./anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing_extensions, sniffio, outcome, h11, wsproto, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.6.3\n",
      "    Uninstalling typing_extensions-4.6.3:\n",
      "      Successfully uninstalled typing_extensions-4.6.3\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.18.1 sniffio-1.3.1 trio-0.24.0 trio-websocket-0.11.1 typing_extensions-4.10.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "72d34d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e160e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57875677",
   "metadata": {},
   "source": [
    "# Q1: In this question you have to scrape data using the filters available on the webpage You have to use the location and\n",
    "salary filter.\n",
    "\n",
    "You have to scrape data for ‚ÄúData Scientist‚Äù designation for first 10 job results.\n",
    "\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "\n",
    "The location filter to be used is ‚ÄúDelhi/NCR‚Äù. The salary filter to be used is ‚Äú3-6‚Äù lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42220d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a64f5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50a6e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c538e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"//label[@class='styles_chkLbl__n2x09']/p/span[contains(text(),'Delhi / NCR')]\")\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3b836f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary=driver.find_element(By.XPATH,\"//label[@class='styles_chkLbl__n2x09']/p/span[contains(text(),'3-6 Lakhs')]\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6591201",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = [i.text for i in driver.find_elements(By.XPATH,'//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/a ')[:10]]  \n",
    "location = [i.text for i in driver.find_elements(By.XPATH, '//span[@class=\"locWdth\"]')[:10]]\n",
    "company = [i.text for i in driver.find_elements(By.XPATH, '//div[@class=\" row2\"]/span/a[1]')[:10]]\n",
    "experience = [i.text for i in driver.find_elements(By.XPATH,'//span[@class=\"expwdth\"]')[:10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7c1bbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6bf74409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist HTHD</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Ford</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Hyderabad, Gurugram</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram, Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>Greater Noida, Bengaluru</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Elitefit.ai</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>Fort Technologies</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Customer Success - Data Scientist</td>\n",
       "      <td>Pune, Gurugram</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fullstack Data Scientist</td>\n",
       "      <td>Mumbai, Gurugram, Bengaluru</td>\n",
       "      <td>Course5 Intelligence</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Times Internet</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title  \\\n",
       "0                     Data Scientist HTHD   \n",
       "1                          Data Scientist   \n",
       "2                          Data Scientist   \n",
       "3                       Data Scientist II   \n",
       "4                     Lead Data Scientist   \n",
       "5                          Data Scientist   \n",
       "6  Lead Customer Success - Data Scientist   \n",
       "7                Fullstack Data Scientist   \n",
       "8                          Data Scientist   \n",
       "9                          Data Scientist   \n",
       "\n",
       "                                            location               company  \\\n",
       "0  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...                  Ford   \n",
       "1                        Mumbai, Hyderabad, Gurugram              Deloitte   \n",
       "2                                Gurugram, Bengaluru             Blackbuck   \n",
       "3                           Greater Noida, Bengaluru             Honeywell   \n",
       "4  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...           Elitefit.ai   \n",
       "5  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...     Fort Technologies   \n",
       "6                                     Pune, Gurugram         ZS Associates   \n",
       "7                        Mumbai, Gurugram, Bengaluru  Course5 Intelligence   \n",
       "8                                              Noida            Innovaccer   \n",
       "9                                              Noida        Times Internet   \n",
       "\n",
       "  experience  \n",
       "0    1-4 Yrs  \n",
       "1    3-6 Yrs  \n",
       "2    3-7 Yrs  \n",
       "3    3-6 Yrs  \n",
       "4    3-7 Yrs  \n",
       "5    1-3 Yrs  \n",
       "6    2-4 Yrs  \n",
       "7    3-6 Yrs  \n",
       "8    2-7 Yrs  \n",
       "9    3-8 Yrs  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'title':title,'location':location,'company':company,'experience':experience})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a239840",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1f540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfe1fb71",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for ‚ÄúData Scientist‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the\n",
    "job-title, \n",
    "\n",
    "job-location, \n",
    "\n",
    "company_name, \n",
    "\n",
    "experience_required. \n",
    "\n",
    "You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a761e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19208c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.NAME,\"id_q\")\n",
    "designation.clear()\n",
    "designation.send_keys('Data Analyst')\n",
    "\n",
    "location=driver.find_element(By.ID,\"id_loc\")\n",
    "location.clear()\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db211b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element(By.CLASS_NAME, \"btn.btn-secondary.undefined\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6c70447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = [i.text for i in driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard__jjUmu  white-box-border jobCard\"]/div/h2')[:10]]  \n",
    "location = [i.text.split('\\n')[0] for i in driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')[:10]]\n",
    "company_name = [i.text for i in driver.find_elements(By.XPATH, '//div[@class=\"jobCard_jobCard_cName__mYnow\"]')[:10]]\n",
    "experience = [i.text for i in driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')[:10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "13790026",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'job-title':title,'job-location':location,'company_name':company_name,'experience_required':experience})\n",
    "df\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa27064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28d11006",
   "metadata": {},
   "source": [
    "# Q3: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/\n",
    "itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=F\n",
    "LIPKART\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "\n",
    "    1. Rating\n",
    "\n",
    "    2. Review summary\n",
    "\n",
    "    3. Full review\n",
    "\n",
    "    4. You have to scrape this data for first 100reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e338fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f7513ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "ReviewSummary =[]\n",
    "FullReview=[]\n",
    "\n",
    "for page in range(0,10):\n",
    "    rating_5= driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_5:\n",
    "        Rating.append(i.text)\n",
    "        \n",
    "    rating_1= driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1rdVr6 _1BLPMq\"]')\n",
    "    for i in rating_1:\n",
    "        Rating.append(i.text)   \n",
    "    reviewSummary =  driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "    for i in reviewSummary:\n",
    "        ReviewSummary.append(i.text)\n",
    "        \n",
    "    fullReview = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]/div/div')\n",
    "    for i in fullReview:\n",
    "        FullReview.append(i.text)\n",
    "        \n",
    "    next_button = driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "564e229f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good Camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Feeling awesome after getting the delivery of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Superüî• and good performance üëå‚ù§Ô∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Daylight Camera quality is best at this price ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Good product, and nice camera nice futures I l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>I like it performance and I like it display qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>I got this mobile in big billiondays sale\\nTru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Outstanding I loved it ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Review summary  \\\n",
       "0       5    Best in the market!   \n",
       "1       5      Worth every penny   \n",
       "2       5         Classy product   \n",
       "3       5               Terrific   \n",
       "4       5              Fabulous!   \n",
       "..    ...                    ...   \n",
       "95      5         Simply awesome   \n",
       "96      5         Simply awesome   \n",
       "97      5  Mind-blowing purchase   \n",
       "98      5              Must buy!   \n",
       "99      5              Wonderful   \n",
       "\n",
       "                                          Full review  \n",
       "0                                         Good Camera  \n",
       "1   Feeling awesome after getting the delivery of ...  \n",
       "2   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "3                                      Very very good  \n",
       "4                     Superüî• and good performance üëå‚ù§Ô∏è  \n",
       "..                                                ...  \n",
       "95  Daylight Camera quality is best at this price ...  \n",
       "96  Good product, and nice camera nice futures I l...  \n",
       "97  I like it performance and I like it display qu...  \n",
       "98  I got this mobile in big billiondays sale\\nTru...  \n",
       "99                    Outstanding I loved it ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rating':Rating,'Review summary':ReviewSummary,'Full review':FullReview})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3960d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a91c9",
   "metadata": {},
   "source": [
    "# Q4: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for ‚Äúsneakers‚Äù in the search field.\n",
    "\n",
    "    You have to scrape 3 attributes of each sneaker:\n",
    "\n",
    "        1. Brand\n",
    "\n",
    "        2. Product Description\n",
    "\n",
    "        3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "56781861",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.flipkart.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "012a4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"Pke_EE\")\n",
    "search.clear()\n",
    "search.send_keys('sneakers')\n",
    "search.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1e06a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "ProductDescription =[]\n",
    "Price=[]\n",
    "\n",
    "for page in range(0,3):\n",
    "    brand= driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand:\n",
    "        Brand.append(i.text)\n",
    "          \n",
    "    productDescription =  driver.find_elements(By.XPATH, '//div[@class=\"_2B099V\"]/a[1]')\n",
    "    for i in productDescription:\n",
    "        ProductDescription.append(i.text)\n",
    "        \n",
    "    price = driver.find_elements(By.XPATH, '//div[@class=\"_2B099V\"]/a[2]/div/div[1]')\n",
    "    for i in price:\n",
    "        Price.append(i.text)\n",
    "        \n",
    "    next_button = driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    next_button.click()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f4ab5c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes for mens Sneakers...</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>‚Çπ439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Trending Stylish Casual Outdoor Shoes For Men ...</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Casual Sneakers Shoes for Men | Soft Cushioned...</td>\n",
       "      <td>‚Çπ1,179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Pacer Future Web Sneakers For Men</td>\n",
       "      <td>‚Çπ2,579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Fire run Sneakers For Men</td>\n",
       "      <td>‚Çπ1,439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Koburg</td>\n",
       "      <td>Daper Sneakers For Men</td>\n",
       "      <td>‚Çπ749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Ivana Wn's Sneakers For Women</td>\n",
       "      <td>‚Çπ1,919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>New Balance</td>\n",
       "      <td>574 Sneakers For Men</td>\n",
       "      <td>‚Çπ4,300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                Product Description   Price\n",
       "0         BRUTON  Combo Pack Of 2 Casual Shoes for mens Sneakers...    ‚Çπ499\n",
       "1         BRUTON      Combo Pack Of 2 Casual Shoes Sneakers For Men    ‚Çπ499\n",
       "2      Deals4you                                 Sneakers For Women    ‚Çπ439\n",
       "3       URBANBOX  Trending Stylish Casual Outdoor Shoes For Men ...    ‚Çπ299\n",
       "4       RED TAPE  Casual Sneakers Shoes for Men | Soft Cushioned...  ‚Çπ1,179\n",
       "..           ...                                                ...     ...\n",
       "115         PUMA                  Pacer Future Web Sneakers For Men  ‚Çπ2,579\n",
       "116         PUMA                          Fire run Sneakers For Men  ‚Çπ1,439\n",
       "117       Koburg                             Daper Sneakers For Men    ‚Çπ749\n",
       "118         PUMA                      Ivana Wn's Sneakers For Women  ‚Çπ1,919\n",
       "119  New Balance                               574 Sneakers For Men  ‚Çπ4,300\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand':Brand,'Product Description':ProductDescription,'Price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4af8f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942ca18c",
   "metadata": {},
   "source": [
    "# Q5: Go to webpage https://www.amazon.in/ Enter ‚ÄúLaptop‚Äù in the search field \n",
    "    and then click the search icon. Then set CPU Type filter to ‚ÄúIntel Core i7‚Äù as shown in the below image:\n",
    "            \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "\n",
    "    1. Title\n",
    "\n",
    "    2. Ratings\n",
    "\n",
    "    3. Price            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "056c4515",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "51ad6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'//div[@class=\"nav-search-field \"]/input')\n",
    "search.clear()\n",
    "search.send_keys('Laptop')\n",
    "search.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b762a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_filter=driver.find_element(By.XPATH,'//span[@class=\"a-declarative\"]/span/li/span/a/span[contains(text(),\"Intel Core i7\")]')\n",
    "CPU_filter.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "376dc260",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = [i.text for i in driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')[:10]]  \n",
    "Ratings = [i.text for i in driver.find_elements(By.XPATH, '//span[@class=\"a-icon-alt\"]')[:10]]\n",
    "Price = [i.text for i in driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')[:10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4db4d7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...</td>\n",
       "      <td></td>\n",
       "      <td>69,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i7 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...</td>\n",
       "      <td></td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo Yoga Slim7 Carbon Intel Evo i7 1260P 13...</td>\n",
       "      <td></td>\n",
       "      <td>74,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acer Travelmate Business Laptop Intel Core i7-...</td>\n",
       "      <td></td>\n",
       "      <td>1,19,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td></td>\n",
       "      <td>49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion X360 11th Gen Intel Core i7 14\" (3...</td>\n",
       "      <td></td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Victus Gaming Laptop, 12th Gen Intel Core i...</td>\n",
       "      <td></td>\n",
       "      <td>67,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td></td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acer Aspire 5 Gaming Laptop Intel Core i7 13th...</td>\n",
       "      <td></td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title Ratings     Price\n",
       "0  MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...            69,990\n",
       "1  Lenovo IdeaPad Slim 3 Intel Core i7 12th Gen 1...            49,990\n",
       "2  ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...            62,990\n",
       "3  Lenovo Yoga Slim7 Carbon Intel Evo i7 1260P 13...            74,990\n",
       "4  Acer Travelmate Business Laptop Intel Core i7-...          1,19,990\n",
       "5  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...            49,990\n",
       "6  HP Pavilion X360 11th Gen Intel Core i7 14\" (3...            59,990\n",
       "7  HP Victus Gaming Laptop, 12th Gen Intel Core i...            67,990\n",
       "8  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...            79,990\n",
       "9  Acer Aspire 5 Gaming Laptop Intel Core i7 13th...            77,990"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'title':title,'Ratings':Ratings,'Price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "15d04151",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d0cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2100dec0",
   "metadata": {},
   "source": [
    "# Q6: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "\n",
    "    The above task will be done in following steps:\n",
    "\n",
    "        1. First get the webpagehttps://www.azquotes.com/\n",
    "\n",
    "        2. Click on Top Quote\n",
    "\n",
    "        3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3fa5f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "45318a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div[2]/div/div/div[2]/div/div[1]/div/div[1]/div/div[3]/div/div[1]/p/a\")\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "667d52ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quote = [i.text for i in driver.find_elements(By.XPATH,'//p[@class=\"single-quote\"]')]  \n",
    "Author = [i.text for i in driver.find_elements(By.XPATH, '//div[@class=\"author\"]/a')]\n",
    "TypeOfQuotes = [i.text for i in driver.find_elements(By.XPATH, '//span[@class=\"small_source_14\"]')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "73561388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>TypeOfQuotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do not plan for ventures before finishing what...</td>\n",
       "      <td>Euripides</td>\n",
       "      <td>Aeschylus, Sophocles, Euripides (1959). ‚ÄúEurip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Quote     Author  \\\n",
       "0  Do not plan for ventures before finishing what...  Euripides   \n",
       "\n",
       "                                        TypeOfQuotes  \n",
       "0  Aeschylus, Sophocles, Euripides (1959). ‚ÄúEurip...  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Quote':Quote,'Author':Author,'TypeOfQuotes':TypeOfQuotes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8bef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
